{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "5afee340",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7159161c",
   "metadata": {},
   "source": [
    "Reading data set from csv file and printing the first five rows to see what the dataset looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "8aed5895",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment_confidence</th>\n",
       "      <th>negativereason</th>\n",
       "      <th>negativereason_confidence</th>\n",
       "      <th>airline</th>\n",
       "      <th>airline_sentiment_gold</th>\n",
       "      <th>name</th>\n",
       "      <th>negativereason_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>570306133677760513</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cairdin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:35:52 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>570301130888122368</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.3486</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:59 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>570301083672813571</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yvonnalynn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:48 -0800</td>\n",
       "      <td>Lets Play</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>570301031407624196</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Bad Flight</td>\n",
       "      <td>0.7033</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:36 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>570300817074462722</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Can't Tell</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:14:45 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id airline_sentiment  airline_sentiment_confidence  \\\n",
       "0  570306133677760513           neutral                        1.0000   \n",
       "1  570301130888122368          positive                        0.3486   \n",
       "2  570301083672813571           neutral                        0.6837   \n",
       "3  570301031407624196          negative                        1.0000   \n",
       "4  570300817074462722          negative                        1.0000   \n",
       "\n",
       "  negativereason  negativereason_confidence         airline  \\\n",
       "0            NaN                        NaN  Virgin America   \n",
       "1            NaN                     0.0000  Virgin America   \n",
       "2            NaN                        NaN  Virgin America   \n",
       "3     Bad Flight                     0.7033  Virgin America   \n",
       "4     Can't Tell                     1.0000  Virgin America   \n",
       "\n",
       "  airline_sentiment_gold        name negativereason_gold  retweet_count  \\\n",
       "0                    NaN     cairdin                 NaN              0   \n",
       "1                    NaN    jnardino                 NaN              0   \n",
       "2                    NaN  yvonnalynn                 NaN              0   \n",
       "3                    NaN    jnardino                 NaN              0   \n",
       "4                    NaN    jnardino                 NaN              0   \n",
       "\n",
       "                                                text tweet_coord  \\\n",
       "0                @VirginAmerica What @dhepburn said.         NaN   \n",
       "1  @VirginAmerica plus you've added commercials t...         NaN   \n",
       "2  @VirginAmerica I didn't today... Must mean I n...         NaN   \n",
       "3  @VirginAmerica it's really aggressive to blast...         NaN   \n",
       "4  @VirginAmerica and it's a really big bad thing...         NaN   \n",
       "\n",
       "               tweet_created tweet_location               user_timezone  \n",
       "0  2015-02-24 11:35:52 -0800            NaN  Eastern Time (US & Canada)  \n",
       "1  2015-02-24 11:15:59 -0800            NaN  Pacific Time (US & Canada)  \n",
       "2  2015-02-24 11:15:48 -0800      Lets Play  Central Time (US & Canada)  \n",
       "3  2015-02-24 11:15:36 -0800            NaN  Pacific Time (US & Canada)  \n",
       "4  2015-02-24 11:14:45 -0800            NaN  Pacific Time (US & Canada)  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Tweets.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669d9ae2",
   "metadata": {},
   "source": [
    "Check for missing data and see what data types are available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "5ee793c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14640 entries, 0 to 14639\n",
      "Data columns (total 15 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   tweet_id                      14640 non-null  int64  \n",
      " 1   airline_sentiment             14640 non-null  object \n",
      " 2   airline_sentiment_confidence  14640 non-null  float64\n",
      " 3   negativereason                9178 non-null   object \n",
      " 4   negativereason_confidence     10522 non-null  float64\n",
      " 5   airline                       14640 non-null  object \n",
      " 6   airline_sentiment_gold        40 non-null     object \n",
      " 7   name                          14640 non-null  object \n",
      " 8   negativereason_gold           32 non-null     object \n",
      " 9   retweet_count                 14640 non-null  int64  \n",
      " 10  text                          14640 non-null  object \n",
      " 11  tweet_coord                   1019 non-null   object \n",
      " 12  tweet_created                 14640 non-null  object \n",
      " 13  tweet_location                9907 non-null   object \n",
      " 14  user_timezone                 9820 non-null   object \n",
      "dtypes: float64(2), int64(2), object(11)\n",
      "memory usage: 1.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01a015f",
   "metadata": {},
   "source": [
    "Remove tweets that have less than 100% confidence in provided sentiment.  This decision was made to help with model accuracy.  Without high confidence we could be training the model to predict incorrectly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "9c860238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10445\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "\n",
    "for i, value in df[\"airline_sentiment_confidence\"].items():\n",
    "    if value >= 1:\n",
    "        count = count + 1\n",
    "    else:\n",
    "        df.drop(i, inplace = True)\n",
    "\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111ee8af",
   "metadata": {},
   "source": [
    "See how many of the remaining tweets are positive, neutral, and negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "2456810e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "negative    7382\n",
       "neutral     1548\n",
       "positive    1515\n",
       "Name: airline_sentiment, dtype: int64"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.airline_sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeab34dc",
   "metadata": {},
   "source": [
    "Set X to tweets and y to sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "835b72a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.text\n",
    "y = df.airline_sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3634af",
   "metadata": {},
   "source": [
    "It is clear the data needs to be cleaned.  We opted to do this manually as it was still fairly simple and it can be hard to speak to exactly what is happening when utilizing the tools available for data cleaning.  The code below iterates through each tweet in the data set.  First, the string is split into individual words, then all punctuation and special characters are removed.  Next, all characters are converted to lowercase.  Finally, the words are joined back into a string.\n",
    "\n",
    "We mostly knew what needed to be done here, but the following resource was used to help figure out the correct syntax in python: https://machinelearningmastery.com/clean-text-machine-learning-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "bf313fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = str.maketrans('', '', string.punctuation)\n",
    "\n",
    "#remove emojis\n",
    "emoji_pattern = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "\n",
    "for i, value in X.items():\n",
    "    value = re.sub('(RT\\s@[A-Za-z]+[A-Za-z0-9-_]+)', '', value)  # remove re-tweet\n",
    "    value = re.sub(r'http\\S+', '', value)   # remove http links\n",
    "    value = re.sub(r'bit.ly/\\S+', '', value)  # remove bitly links\n",
    "    value = emoji_pattern.sub(r'', value)\n",
    "    value = value.split()\n",
    "    value = [w.translate(table) for w in value]\n",
    "    value = [w.lower() for w in value]\n",
    "    X[i] = ' '.join(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec408e9b",
   "metadata": {},
   "source": [
    "Split into train and test sets.  There are only 10445 remaining tweets so we opted to set the training set to 70% and the test set to 30%.  We also set the random state attribute so our results could be reproduced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "439ef525",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a57f72",
   "metadata": {},
   "source": [
    "Print the number of positive, negative, and neutral tweets in train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "7ef3601a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negative    5173\n",
      "neutral     1082\n",
      "positive    1056\n",
      "Name: airline_sentiment, dtype: int64\n",
      "#########\n",
      "negative    2209\n",
      "neutral      466\n",
      "positive     459\n",
      "Name: airline_sentiment, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(y_train.value_counts())\n",
    "print('#########')\n",
    "print(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43e7998",
   "metadata": {},
   "source": [
    "Print the training set tweets to ensure the tweets have been cleaned before vectorizing and setting up tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "db2af99b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1568     united deceptive marketing practices promised ...\n",
       "8331     jetblue pooling and gifting are completely dif...\n",
       "10552    usairways what happens if the flight takes off...\n",
       "1629     united everytime i fly ur airline i hate you e...\n",
       "10834    usairways call volumes are high so the best an...\n",
       "                               ...                        \n",
       "1578     united is it possible to add a known traveler ...\n",
       "3532     united unavailable leg that registered hours a...\n",
       "9695     usairways americanair have the most rude unrel...\n",
       "3626     united omg where is my bag yyzua70435  enough ...\n",
       "10547    usairways enormous lines at customer service a...\n",
       "Name: text, Length: 7311, dtype: object"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb987b53",
   "metadata": {},
   "source": [
    "Tfidf_vectorizer combines the count vectorizer and tfidf steps for simplicity. After we fit our tfidf vectorizer with the training tweets and transform both train and test set tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "a54d8762",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(max_features=500, stop_words='english')\n",
    "\n",
    "X_train = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test  = tfidf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0c2ab9",
   "metadata": {},
   "source": [
    "Create logistic regression model with 5 fold cross validation for classification.  Fit the model with the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "362267ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegressionCV(cv=5, max_iter=2500, n_jobs=-1)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LRmodel = LogisticRegressionCV(cv=5, max_iter = 2500, n_jobs=-1)\n",
    "LRmodel.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b387909f",
   "metadata": {},
   "source": [
    "Lastly, we test the model on training and test sets, printing accuracy, precision, recall, and F1 scores as well as a confusion matrix.  We can see the model is likely not overfitted because the training and test accuracy scores are not wildly different.  It is expected the training score should be better than test as the model was fitted with training data.  From the results we can see the model accurately predicts 83% of the test tweets.  Further inspection with precision, recall and F1 reveals the model performs the best on the negative tweets which makes sense as there are a lot more negative tweets then positive/neutral tweets.  Precision, how accurate the model is considering true positives/predicted positives, is fairly close for both positive and negative tweets in the mid 80's, but is much lower for neutral tweets.  This is harder to explain, but there seems to be a fine line between neutral and positive or negative, and neutral tweets have limited training data, so it follows this would be the hardest category for the model to predict.  Recall, how accurate the model is considering true positives/actual positives, is very good for negative tweets, but steps down for positive tweets, and then down further for neutral tweets.  Recall is probably the best measure here if the airline intends to follow up with disgruntled customers or make changes based on negative feedback.  Fortunately, the subset of interest would be the negative tweets which has a 94% recall score, so our model is quite effective at capturing true negative tweets.  The confusion matrix was added to help visualize precision/recall across our model.\n",
    "\n",
    "We used all of this in assignments troughout the semester so no resources were needed for this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "67b507af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy:  0.8756668034468609\n",
      "Test accuracy:  0.8270580727504786\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.94      0.90      2209\n",
      "     neutral       0.62      0.46      0.53       466\n",
      "    positive       0.80      0.65      0.72       459\n",
      "\n",
      "    accuracy                           0.83      3134\n",
      "   macro avg       0.76      0.68      0.72      3134\n",
      "weighted avg       0.82      0.83      0.82      3134\n",
      "\n",
      "Confusion Matrix:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred:negative</th>\n",
       "      <th>pred:neutral</th>\n",
       "      <th>pred:positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>actual:negative</th>\n",
       "      <td>2080</td>\n",
       "      <td>88</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual:neutral</th>\n",
       "      <td>219</td>\n",
       "      <td>215</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual:positive</th>\n",
       "      <td>121</td>\n",
       "      <td>41</td>\n",
       "      <td>297</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 pred:negative  pred:neutral  pred:positive\n",
       "actual:negative           2080            88             41\n",
       "actual:neutral             219           215             32\n",
       "actual:positive            121            41            297"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make predictions on test data\n",
    "predicted_train = LRmodel.predict(X_train)\n",
    "predicted_test = LRmodel.predict(X_test)\n",
    "\n",
    "LRmodel_train_accuracy = (np.mean(predicted_train == y_train)) \n",
    "print(\"Training accuracy: \", LRmodel_train_accuracy)\n",
    "LRmodel_test_accuracy = (np.mean(predicted_test == y_test)) \n",
    "print(\"Test accuracy: \", LRmodel_test_accuracy)\n",
    "print()\n",
    "\n",
    "# print precision and recall statistics\n",
    "print(metrics.classification_report(y_test, predicted_test))\n",
    "\n",
    "# print confusion matrix\n",
    "print(\"Confusion Matrix:\\n\")\n",
    "pd.DataFrame(\n",
    "    metrics.confusion_matrix(y_test, predicted_test),\n",
    "    index=['actual:negative', 'actual:neutral', 'actual:positive'], \n",
    "    columns=['pred:negative', 'pred:neutral', 'pred:positive']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db730f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
